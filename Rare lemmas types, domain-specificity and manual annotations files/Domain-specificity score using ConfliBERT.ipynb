{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f67a413b-1407-42b2-80ed-9b06ae378298",
   "metadata": {},
   "source": [
    "B.L.\n",
    "This script will score your list of words by giving them a domain-specificity score based on the reference set we crafted manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8d184e-5a4b-407d-a41e-bf00042ba2e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b11fb9053e84416b3fb2d05631d48e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 19:16:09 INFO: Downloaded file to C:\\Users\\brike\\stanza_resources\\resources.json\n",
      "2025-05-27 19:16:09 INFO: Downloading default packages for language: en (English) ...\n",
      "2025-05-27 19:16:11 INFO: File exists: C:\\Users\\brike\\stanza_resources\\en\\default.zip\n",
      "2025-05-27 19:16:14 INFO: Finished downloading models and saved to C:\\Users\\brike\\stanza_resources\n",
      "2025-05-27 19:16:14 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a889bf22b226481ca37fe0439b6790c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json:   0%|  …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-27 19:16:15 INFO: Downloaded file to C:\\Users\\brike\\stanza_resources\\resources.json\n",
      "2025-05-27 19:16:15 WARNING: Language en package default expects mwt, which has been added\n",
      "2025-05-27 19:16:15 INFO: Loading these models for language: en (English):\n",
      "=================================\n",
      "| Processor | Package           |\n",
      "---------------------------------\n",
      "| tokenize  | combined          |\n",
      "| mwt       | combined          |\n",
      "| lemma     | combined_nocharlm |\n",
      "=================================\n",
      "\n",
      "2025-05-27 19:16:15 INFO: Using device: cpu\n",
      "2025-05-27 19:16:15 INFO: Loading: tokenize\n",
      "2025-05-27 19:16:15 INFO: Loading: mwt\n",
      "2025-05-27 19:16:15 INFO: Loading: lemma\n",
      "2025-05-27 19:16:16 INFO: Done loading processors!\n",
      "Some weights of BertModel were not initialized from the model checkpoint at snowood1/ConfliBERT-cont-uncased and are newly initialized: ['pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Encoding terms:   0%|                                                                           | 0/19 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Encoding terms: 100%|██████████████████████████████████████████████████████████████████| 19/19 [00:02<00:00,  6.36it/s]\n",
      "Calculating similarity scores: 100%|███████████████████████████████████████████████| 3369/3369 [02:12<00:00, 25.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity calculation complete. Results saved to C:\\Users\\brike\\OneDrive\\Desktop\\RA\\Upload projekti\\domain_terms_similarity_scored.xlsx.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import stanza\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "from tqdm import tqdm\n",
    "\n",
    "#Stanza pipeline\n",
    "stanza.download('en')\n",
    "nlp = stanza.Pipeline(lang='en', processors='tokenize,lemma', use_gpu=torch.cuda.is_available())\n",
    "\n",
    "#loading ConfliBERT\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"snowood1/ConfliBERT-cont-uncased\")\n",
    "model = AutoModel.from_pretrained(\"snowood1/ConfliBERT-cont-uncased\").eval()\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "#loading the Excel file where in the first column is the reference set (in the Github), \n",
    "#in the second column will be the list of words from your dataset (you will have this list ready after using the script:\n",
    "#\"Create resouces, automatic annotation for domain,rare and comparison.ipynb\", which is included in the Github repo.\n",
    "\n",
    "file_path = r\"List of domain specific (reference set and the extended one).xlsx\"\n",
    "df = pd.read_excel(file_path)\n",
    "\n",
    "#extract columns\n",
    "reference_terms = df.iloc[:, 0].dropna().unique().tolist()\n",
    "domain_specific_terms = df.iloc[:, 1].tolist()\n",
    "\n",
    "# Compute embeddings for reference terms (efficient batching)\n",
    "def get_embeddings(terms):\n",
    "    embeddings = []\n",
    "    batch_size = 32\n",
    "    for i in tqdm(range(0, len(terms), batch_size), desc=\"Encoding terms\"):\n",
    "        batch = terms[i:i + batch_size]\n",
    "        encoded = tokenizer(batch, return_tensors='pt', padding=True, truncation=True)\n",
    "        output = model(**encoded)\n",
    "        masked = output.last_hidden_state * encoded['attention_mask'].unsqueeze(-1)\n",
    "        embeddings_batch = (masked.sum(dim=1) / encoded['attention_mask'].sum(dim=1, keepdim=True))\n",
    "        embeddings_batch = embeddings_batch / embeddings_batch.norm(dim=1, keepdim=True)\n",
    "        embeddings.append(embeddings_batch)\n",
    "    return torch.cat(embeddings)\n",
    "\n",
    "ref_embeddings = get_embeddings(reference_terms)\n",
    "\n",
    "#similarity function using stanza lemmatization\n",
    "def calculate_similarity(term):\n",
    "    if pd.isna(term) or not isinstance(term, str) or term.strip() == \"\":\n",
    "        return 0.0\n",
    "    \n",
    "    #lemmatize the term using stanza\n",
    "    doc = nlp(term)\n",
    "    lemmas = [word.lemma.lower() for sent in doc.sentences for word in sent.words if word.lemma.isalpha()]\n",
    "    if not lemmas:\n",
    "        return 0.0\n",
    "    \n",
    "    lemma_embeddings = []\n",
    "    for lemma in lemmas:\n",
    "        encoded = tokenizer(lemma, return_tensors=\"pt\")\n",
    "        output = model(**encoded)\n",
    "        lemma_embedding = output.last_hidden_state.mean(dim=1)\n",
    "        lemma_embedding = lemma_embedding / lemma_embedding.norm(p=2, dim=1, keepdim=True)\n",
    "        lemma_embeddings.append(lemma_embedding[0])\n",
    "\n",
    "    lemma_embeddings = torch.stack(lemma_embeddings)\n",
    "    cosine_similarities = torch.mm(lemma_embeddings, ref_embeddings.T)\n",
    "    max_sims = cosine_similarities.max(dim=1).values\n",
    "    return round(max_sims.mean().item(), 3)\n",
    "\n",
    "#apply similarity calculation and store in column 'c'\n",
    "tqdm.pandas(desc=\"Calculating similarity scores\")\n",
    "df['c'] = df.iloc[:, 1].progress_apply(calculate_similarity)\n",
    "\n",
    "#save updated Excel file\n",
    "output_file_path = r\"domain_terms_similarity_scored.xlsx\"\n",
    "df.to_excel(output_file_path, index=False)\n",
    "\n",
    "print(f\"Similarity calculation complete. Results saved to {output_file_path}.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff96ca-339c-4036-af4d-b9fc24331125",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
